# Copyright (C) 2020-2025 Motphys Technology Co., Ltd. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ==============================================================================

import gymnasium as gym
import motrixsim as mtx
import numpy as np
import os

from motrix_envs import registry
from motrix_envs.np.env import NpEnv, NpEnvState
from motrix_envs.math.quaternion import Quaternion

from .cfg import AnymalCRoughEnvCfg

@registry.env("anymal_c_navigation_rough","np")
class AnymalCRoughEnv(NpEnv):
    _cfg: AnymalCRoughEnvCfg

    def __init__(self, cfg:AnymalCRoughEnvCfg, num_envs: int = 1):
        super().__init__(cfg, num_envs = num_envs)
        self._init_action_space()
        self._init_obs_space()
        self._init_contact_geometry()
        self._init_body()
    
        # å½’ä¸€åŒ–ç³»æ•°
        self.commands_scale = np.array(
            [cfg.normalization.lin_vel, cfg.normalization.lin_vel, cfg.normalization.ang_vel],
            dtype=np.float32
        )
        self._num_dof_pos = self._model.num_dof_pos
        self._num_dof_vel = self._model.num_dof_vel
        self._num_action = self._model.num_actuators

        self._init_dof_pos = self._model.compute_init_dof_pos()
        self._init_dof_vel = np.zeros(
            (self._model.num_dof_vel,),
            dtype=np.float32,
        ) 
        self._setup_init_dof_pos()

    def _init_action_space(self):
        self._action_space = gym.spaces.Box(low = -1.0, high = 1.0, shape = (12,), dtype = np.float32)

     # è§‚æµ‹ç©ºé—´ï¼šlinvel(3) + gyro(3) + gravity(3) + joint_pos(12) + joint_vel(12) + last_actions(12) + commands(3) + position_error(2) + heading_error(1) + distance(1) + reached_flag(1) + stop_ready_flag(1) = 54
        '''
        linvel (3)ï¼šçº¿æ€§é€Ÿåº¦ (3)
        è§£é‡Šï¼šè¡¨ç¤ºæœºå™¨äººçš„ä¸‰ç»´çº¿æ€§é€Ÿåº¦ï¼Œé€šå¸¸åŒ…æ‹¬ Xã€Y å’Œ Z è½´çš„é€Ÿåº¦åˆ†é‡ã€‚

        gyro (3)ï¼šé™€èºä»ª (3)
        è§£é‡Šï¼šè¡¨ç¤ºæœºå™¨äººçš„æ—‹è½¬é€Ÿåº¦ï¼Œé€šå¸¸åŒ…æ‹¬ç»• Xã€Y å’Œ Z è½´çš„è§’é€Ÿåº¦åˆ†é‡ã€‚

        gravity (3)ï¼šé‡åŠ› (3)
        è§£é‡Šï¼šè¡¨ç¤ºæœºå™¨äººçš„é‡åŠ›æ–¹å‘ï¼Œé€šå¸¸ç”¨äºæè¿°é‡åŠ›çš„ä¸‰ç»´åˆ†é‡ï¼Œé€šå¸¸ä¸ºä¸‰ä¸ªå€¼ï¼šæ²¿ç€ Xã€Y å’Œ Z è½´çš„é‡åŠ›åˆ†é‡ã€‚

        joint_pos (12)ï¼šå…³èŠ‚ä½ç½® (12)
        è§£é‡Šï¼šè¡¨ç¤ºæœºå™¨äººçš„ 12 ä¸ªå…³èŠ‚çš„ä½ç½®ï¼Œé€šå¸¸ç”¨äºæè¿°æœºå™¨äººçš„æ¯ä¸ªå…³èŠ‚çš„è§’åº¦æˆ–ä½ç½®ã€‚

        joint_vel (12)ï¼šå…³èŠ‚é€Ÿåº¦ (12)
        è§£é‡Šï¼šè¡¨ç¤ºæœºå™¨äººçš„ 12 ä¸ªå…³èŠ‚çš„é€Ÿåº¦ï¼Œé€šå¸¸ç”¨äºæè¿°æ¯ä¸ªå…³èŠ‚çš„è§’é€Ÿåº¦æˆ–çº¿é€Ÿåº¦ã€‚

        last_actions (12)ï¼šä¸Šä¸€æ¬¡åŠ¨ä½œ (12)
        è§£é‡Šï¼šè¡¨ç¤ºæœºå™¨äººä¸Šä¸€æ¬¡æ‰§è¡Œçš„ 12 ä¸ªåŠ¨ä½œï¼Œé€šå¸¸ç”¨äºæ§åˆ¶ç³»ç»Ÿä¸­è®°å½•å…ˆå‰çš„æ§åˆ¶å‘½ä»¤ã€‚

        commands (3)ï¼šæŒ‡ä»¤ (3)
        è§£é‡Šï¼šè¡¨ç¤ºæœºå™¨äººæ¥æ”¶åˆ°çš„æ§åˆ¶æŒ‡ä»¤ï¼Œé€šå¸¸æ˜¯ä¸‰ç»´çš„ï¼Œå¯ä»¥ä»£è¡¨æœºå™¨äººçš„ç›®æ ‡ä½ç½®ã€é€Ÿåº¦æˆ–å…¶ä»–å‚æ•°ã€‚

        position_error (2)ï¼šä½ç½®è¯¯å·® (2)
        è§£é‡Šï¼šè¡¨ç¤ºæœºå™¨äººçš„ä½ç½®è¯¯å·®ï¼Œé€šå¸¸åŒ…æ‹¬ X å’Œ Y è½´ä¸Šçš„è¯¯å·®ï¼Œæˆ–ä¸ç›®æ ‡ä½ç½®çš„åå·®ã€‚

        heading_error (1)ï¼šèˆªå‘è¯¯å·® (1)
        è§£é‡Šï¼šè¡¨ç¤ºæœºå™¨äººçš„èˆªå‘è¯¯å·®ï¼Œé€šå¸¸è¡¨ç¤ºæœºå™¨äººçš„æœå‘ä¸ç›®æ ‡èˆªå‘ä¹‹é—´çš„åå·®ã€‚

        distance (1)ï¼šè·ç¦» (1)
        è§£é‡Šï¼šè¡¨ç¤ºæœºå™¨äººåˆ°ç›®æ ‡çš„è·ç¦»ï¼Œé€šå¸¸ç”¨äºå¯¼èˆªæˆ–è·¯å¾„è§„åˆ’ä»»åŠ¡ä¸­ã€‚

        reached_flag (1)ï¼šåˆ°è¾¾æ ‡å¿— (1)
        è§£é‡Šï¼šè¡¨ç¤ºæœºå™¨äººæ˜¯å¦åˆ°è¾¾äº†ç›®æ ‡ä½ç½®ï¼Œé€šå¸¸æ˜¯ä¸€ä¸ªå¸ƒå°”å€¼ï¼ˆ0 æˆ– 1ï¼‰ã€‚

        stop_ready_flag (1)ï¼šåœæ­¢å‡†å¤‡æ ‡å¿— (1)
        è§£é‡Šï¼šè¡¨ç¤ºæœºå™¨äººæ˜¯å¦å‡†å¤‡å¥½åœæ­¢ï¼Œé€šå¸¸æ˜¯ä¸€ä¸ªå¸ƒå°”å€¼ï¼ˆ0 æˆ– 1ï¼‰ã€‚
        '''
    def _init_obs_space(self):
        self._observation_space = gym.spaces.Box(low = -np.inf, high = np.inf, shape = (54,), dtype = np.float32)

    def  _init_body(self):

        self._body = self._model.get_body(self.cfg.asset.body_name)
        # è·å–ç›®æ ‡æ ‡è®°çš„body
        self._target_marker_body = self._model.get_body("target_marker")
        # è·å–ç®­å¤´bodyï¼ˆç”¨äºå¯è§†åŒ–ï¼Œä¸å½±å“ç‰©ç†ï¼‰
        try:
            self._robot_arrow_body = self._model.get_body("robot_heading_arrow")
            self._desired_arrow_body = self._model.get_body("desired_heading_arrow")
        except Exception as e:
            self._robot_arrow_body = None
            self._desired_arrow_body = None

    def _setup_init_dof_pos(self):
         # DOFç»“æ„ï¼š
        # DOF 0-2: target_marker (3ä¸ª: slide x, slide y, hinge yaw)
        # DOF 3-5: base position (3ä¸ª)
        # DOF 6-9: base quaternion (4ä¸ª)
        # DOF 10-21: joint angles (12ä¸ª)
        # DOF 22-28: robot_heading_arrow freejoint (7ä¸ª: 3 pos + 4 quat)
        # DOF 29-35: desired_heading_arrow freejoint (7ä¸ª: 3 pos + 4 quat)
        self._target_marker_dof_start = 0
        self._target_marker_dof_end = 3
        # baseçš„å››å…ƒæ•°ç´¢å¼•
        self._base_quat_dof_start = 6
        self._base_quat_dof_end = 10

        #å…³èŠ‚è§’çš„ç´¢å¼•
        self._joint_angle_dof_start=10
        self._joint_angle_dof_end=22

         # robot_heading_arrowçš„DOFç´¢å¼•
        self._robot_arrow_dof_start = 22
        self._robot_arrow_dof_end = 29
        
        # desired_heading_arrowçš„DOFç´¢å¼•
        self._desired_arrow_dof_start = 29
        self._desired_arrow_dof_end = 36

        # è®¾ç½®ä¸ç›®æ ‡ä½ç½®çš„åˆå§‹åç§»
        self._init_dof_pos[self._target_marker_dof_start:self._target_marker_dof_end] = [0.0, 0.0, 0.0]  # [x, y, yaw]

        # è®¾ç½®ç®­å¤´çš„åˆå§‹ä½ç½®å’Œå§¿æ€: [x, y, z, qx, qy, qz, qw]
        if self._robot_arrow_dof_end <= len(self._init_dof_pos):
            self._init_dof_pos[self._robot_arrow_dof_start:self._robot_arrow_dof_end] = [0.0, 0.0, 0.76, 0.0, 0.0, 0.0, 1.0]
            
        if self._desired_arrow_dof_end <= len(self._init_dof_pos):
            self._init_dof_pos[self._desired_arrow_dof_start:self._desired_arrow_dof_end] = [0.0, 0.0, 0.76, 0.0, 0.0, 0.0, 1.0]

        # è®¾ç½®é»˜è®¤å…³èŠ‚è§’åº¦
        cfg = self._cfg
        self.default_angles = np.zeros(self._num_action, dtype = np.float32)
        for i in range(self._model.num_actuators):
            for name, angle in cfg.init_state.default_joint_angles.items():
                if name in self._model.actuator_names[i]:
                    self.default_angles[i] = angle
        self._init_dof_pos[self._joint_angle_dof_start: self._joint_angle_dof_end] = self.default_angles
    

    def _init_contact_geometry(self):
        """åˆå§‹åŒ–æ¥è§¦æ£€æµ‹æ‰€éœ€çš„å‡ ä½•ä½“ç´¢å¼•"""
        cfg = self._cfg
        self.ground_index = self._model.get_geom_index(cfg.asset.ground_name)
        
        # åˆå§‹åŒ–æ¥è§¦æ£€æµ‹çŸ©é˜µ
        self._init_termination_contact()
        self._init_foot_contact()

    def _init_termination_contact(self):
        """åˆå§‹åŒ–ç»ˆæ­¢æ¥è§¦æ£€æµ‹"""
        cfg = self._cfg
        # æŸ¥æ‰¾åŸºåº§å‡ ä½•ä½“
        base_indices = []
        for base_name in cfg.asset.terminate_after_contacts_on:
            try:
                base_idx = self._model.get_geom_index(base_name)
                if base_idx is not None:
                    base_indices.append(base_idx)
                else:
                    print(f"Warning: Geom '{base_name}' not found in model")
            except Exception as e:
                print(f"Warning: Error finding base geom '{base_name}': {e}")

        # åˆ›å»ºåŸºåº§-åœ°é¢æ¥è§¦æ£€æµ‹çŸ©é˜µ
        if base_indices:
            self.termination_contact = np.array(
                [[idx, self.ground_index] for idx in base_indices],
                dtype=np.uint32
            )
            self.num_termination_check = self.termination_contact.shape[0]
        else:
            # ä½¿ç”¨ç©ºæ•°ç»„
            self.termination_contact = np.zeros((0, 2), dtype=np.uint32)
            self.num_termination_check = 0
            print("Warning: No base contacts configured for termination")

    def _init_foot_contact(self):
        """åˆå§‹åŒ–è¶³éƒ¨æ¥è§¦æ£€æµ‹"""
        cfg = self._cfg
        foot_indices = []
        for foot_name in cfg.asset.foot_names:
            try:
                foot_idx = self._model.get_geom_index(foot_name)
                if foot_idx is not None:
                    foot_indices.append(foot_idx)
                else:
                    print(f"Warning: Foot geom '{foot_name}' not found in model")
            except Exception as e:
                print(f"Warning: Error finding foot geom '{foot_name}': {e}")
        
        # åˆ›å»ºè¶³éƒ¨-åœ°é¢æ¥è§¦æ£€æµ‹çŸ©é˜µ
        if foot_indices:
            self.foot_contact_check = np.array(
                [[idx, self.ground_index] for idx in foot_indices],
                dtype=np.uint32
            )
            self.num_foot_check = self.foot_contact_check.shape[0]
        else:
            self.foot_contact_check = np.zeros((0, 2), dtype=np.uint32)
            self.num_foot_check = 0
            print("Warning: No foot contacts configured")

    def get_dof_pos(self, data: mtx.SceneData):
        return self._body.get_joint_dof_pos(data)

    def get_dof_vel(self, data: mtx.SceneData):
        return self._body.get_joint_dof_vel(data)

    def _extract_root_state(self, data):
        """
        ä»self._bodyä¸­æå–æ ¹èŠ‚ç‚¹çŠ¶æ€
        """
        pose = self._body.get_pose(data)
        # ä½ç½® [x, y, z]
        root_pos = pose[:, :3]
        # å››å…ƒæ•° [qx, qy, qz, qw] - Motrixå¼•æ“æ ¼å¼
        root_quat = pose[:, 3:7]
        # ä½¿ç”¨ä¼ æ„Ÿå™¨è·å–é€Ÿåº¦
        root_linvel = self.get_local_linvel(data)
        return root_pos, root_quat, root_linvel

    @property
    def observation_space(self):
        return self._observation_space

    @property
    def action_space(self):
        return self._action_space

    def apply_action(self, actions: np.ndarray, state: NpEnvState):              
        # ä¿å­˜å½“å‰actionç”¨äºå¢é‡æ§åˆ¶
        if "current_action" not in state.info:
            state.info["current_actions"] = np.zeros_like(actions)
        state.info["last_dof_vel"] = self.get_dof_vel(state.data)
        state.info['last_actions'] = state.info['current_actions']
        state.info['current_actions'] = actions
        
        state.data.actuator_ctrls = self._compute_torques(actions, state.data)
        return state

    def _compute_torques(self, actions, data):
        # ä½ç½®æ§åˆ¶æ¨¡å¼ï¼šç›´æ¥è¿”å›ç›®æ ‡è§’åº¦ï¼Œè®©MuJoCoçš„PDæ§åˆ¶å™¨å¤„ç†
        # actionè¡¨ç¤ºç›¸å¯¹äºé»˜è®¤è§’åº¦çš„åç§»
        actions_scaled = actions * self._cfg.control_config.action_scale
        
        # ç›®æ ‡å…³èŠ‚è§’ = é»˜è®¤è§’åº¦ + åŠ¨ä½œåç§»
        target_pos = self.default_angles + actions_scaled
        
        # ç›´æ¥è¿”å›ç›®æ ‡ä½ç½®ï¼ŒMuJoCoä¼šæ ¹æ®XMLä¸­çš„kpå’Œkdè®¡ç®—åŠ›çŸ©
        return target_pos

    def update_state(self, state:NpEnvState):
        data = state.data

        pose_commands = state.info["pose_commands"]
        obs = self._compute_obs(state.data,pose_commands,0.3,np.deg2rad(15),state.info["current_actions"])
        
        # è®¡ç®—å¥–åŠ±
        reward = self._compute_reward(state)
        # è®¡ç®—ç»ˆæ­¢æ¡ä»¶
        terminated_state = self._compute_terminated(state)
        terminated = terminated_state.terminated
        
        state.obs = obs
        state.reward = reward
        state.terminated = terminated     
        return state

    def _get_heading_from_quat(self, quat:np.ndarray) -> np.ndarray:
        # Motrixå¼•æ“æ ¼å¼: [qx, qy, qz, qw]
        qx, qy, qz, qw = quat[:, 0], quat[:, 1], quat[:, 2], quat[:, 3]
        # è®¡ç®—yawè§’ï¼ˆç»•Zè½´æ—‹è½¬ï¼‰
        siny_cosp = 2 * (qw * qz + qx * qy)
        cosy_cosp = 1 - 2 * (qy * qy + qz * qz)
        heading = np.arctan2(siny_cosp, cosy_cosp)
        return heading
    
    def _update_heading_arrows(self, data: mtx.SceneData, robot_pos: np.ndarray, desired_vel_xy: np.ndarray, base_lin_vel_xy: np.ndarray):
        """
        æ›´æ–°ç®­å¤´ä½ç½®ï¼ˆä½¿ç”¨DOFæ§åˆ¶freejointï¼Œä¸å½±å“ç‰©ç†ï¼‰
        robot_pos: [num_envs, 3] - æœºå™¨äººä½ç½®
        desired_vel_xy: [num_envs, 2] - æœŸæœ›çº¿é€Ÿåº¦ï¼ˆåœ°é¢åæ ‡ï¼‰
        base_lin_vel_xy: [num_envs, 2] - å®é™…çº¿é€Ÿåº¦ï¼ˆåœ°é¢åæ ‡ï¼‰
        """
        if self._robot_arrow_body is None or self._desired_arrow_body is None:
            return
        
        num_envs = data.shape[0]
        arrow_height = 0.76  # ç®­å¤´é«˜åº¦ï¼ˆbase=0.56 + 0.2ï¼‰
        
        # è·å–æ‰€æœ‰ç¯å¢ƒçš„dof_pos
        all_dof_pos = data.dof_pos.copy()
        
        for env_idx in range(num_envs):
            # å½“å‰è¿åŠ¨æ–¹å‘ç®­å¤´ï¼ˆç»¿è‰²ï¼‰ï¼šç”±å®é™…çº¿é€Ÿåº¦æ–¹å‘å†³å®š
            cur_v = base_lin_vel_xy[env_idx]
            if np.linalg.norm(cur_v) > 1e-3:
                cur_yaw = np.arctan2(cur_v[1], cur_v[0])
            else:
                cur_yaw = 0.0
            robot_arrow_pos = np.array([
                robot_pos[env_idx, 0],
                robot_pos[env_idx, 1],
                arrow_height
            ], dtype=np.float32)
            robot_arrow_quat = self._euler_to_quat(0, 0, cur_yaw)
            quat_norm = np.linalg.norm(robot_arrow_quat)
            if quat_norm > 1e-6:
                robot_arrow_quat = robot_arrow_quat / quat_norm
            all_dof_pos[env_idx, self._robot_arrow_dof_start:self._robot_arrow_dof_end] = np.concatenate([
                robot_arrow_pos, robot_arrow_quat
            ])
            
            # æœŸæœ›è¿åŠ¨æ–¹å‘ç®­å¤´ï¼ˆè“è‰²ï¼‰ï¼šç”±æœŸæœ›çº¿é€Ÿåº¦æ–¹å‘å†³å®š
            des_v = desired_vel_xy[env_idx]
            if np.linalg.norm(des_v) > 1e-3:
                des_yaw = np.arctan2(des_v[1], des_v[0])
            else:
                des_yaw = 0.0
            desired_arrow_pos = np.array([
                robot_pos[env_idx, 0],
                robot_pos[env_idx, 1],
                arrow_height
            ], dtype=np.float32)
            desired_arrow_quat = self._euler_to_quat(0, 0, des_yaw)
            quat_norm = np.linalg.norm(desired_arrow_quat)
            if quat_norm > 1e-6:
                desired_arrow_quat = desired_arrow_quat / quat_norm
            all_dof_pos[env_idx, self._desired_arrow_dof_start:self._desired_arrow_dof_end] = np.concatenate([
                desired_arrow_pos, desired_arrow_quat
            ])
        
        # ä¸€æ¬¡æ€§è®¾ç½®æ‰€æœ‰ç¯å¢ƒçš„dof_pos
        data.set_dof_pos(all_dof_pos, self._model)
        self._model.forward_kinematic(data)
    
    def _quat_multiply(self, q1, q2):
        """Motrixæ ¼å¼å››å…ƒæ•°ä¹˜æ³• [qx, qy, qz, qw]"""
        qx1, qy1, qz1, qw1 = q1[0], q1[1], q1[2], q1[3]
        qx2, qy2, qz2, qw2 = q2[0], q2[1], q2[2], q2[3]
        
        qw = qw1*qw2 - qx1*qx2 - qy1*qy2 - qz1*qz2
        qx = qw1*qx2 + qx1*qw2 + qy1*qz2 - qz1*qy2
        qy = qw1*qy2 - qx1*qz2 + qy1*qw2 + qz1*qx2
        qz = qw1*qz2 + qx1*qy2 - qy1*qx2 + qz1*qw2
        
        return np.array([qx, qy, qz, qw], dtype=np.float32)
    
    def _euler_to_quat(self, roll, pitch, yaw):
        """
        æ¬§æ‹‰è§’è½¬å››å…ƒæ•° [qx, qy, qz, qw] - Motrixæ ¼å¼
        """
        cy = np.cos(yaw * 0.5)
        sy = np.sin(yaw * 0.5)
        cp = np.cos(pitch * 0.5)
        sp = np.sin(pitch * 0.5)
        cr = np.cos(roll * 0.5)
        sr = np.sin(roll * 0.5)
        
        qw = cr * cp * cy + sr * sp * sy
        qx = sr * cp * cy - cr * sp * sy
        qy = cr * sp * cy + sr * cp * sy
        qz = cr * cp * sy - sr * sp * cy
        
        return np.array([qx, qy, qz, qw], dtype=np.float32)
    
    def _compute_reward(self, state:NpEnvState) -> np.ndarray:
        data = state.data
        info = state.info
        desired_vel_xy,desired_vel_xy,reached_all,velocity_commands=self._compute_velocity_commands(0.3,np.deg2rad(15))
        mask = reached_all.astype(np.float32)
        inv = 1.0 - mask

        reward_dict = {
            # always-on
            "lin_vel_z":        self._reward_lin_vel_z(data),
            "ang_vel_xy":       self._reward_ang_vel_xy(data),
            "orientation":      self._reward_orientation(data),
            "torques":          self._reward_torques(data),
            "dof_vel":          self._reward_dof_vel(data),
            "dof_acc":          self._reward_dof_acc(data, info),
            "action_rate":      self._reward_action_rate(info),
            "termination":      self._reward_termination(data),
            "stand_still":      self._reward_stand_still(data, velocity_commands) * inv,

            # æœªåˆ°è¾¾
            "tracking_lin_vel": self._reward_tracking_lin_vel(data, velocity_commands) * inv,
            "tracking_ang_vel": self._reward_tracking_ang_vel(data, velocity_commands) * inv,  
            "approach_reward":  self._reward_approch(info) * inv,

            # å·²åˆ°è¾¾
            "arrival_bonus":    self._reward_arrival_bonus(info, reached_all) * mask,
            "stop_bonus":       self._reward_stop_bonus(data, reached_all) * mask,
        }


        rewards = {k: v * self.cfg.reward_config.scales[k] for k, v in reward_dict.items()}
        rwd = sum(rewards.values())
        # rwd = np.clip(rwd, 0.0, 10000.0)

        return rwd
    
    def _update_target_marker(self, data: mtx.SceneData, pose_commands: np.ndarray):
        """
        æ›´æ–°ç›®æ ‡ä½ç½®æ ‡è®°çš„ä½ç½®å’Œæœå‘
        pose_commands: [num_envs, 3] - (target_x, target_y, target_heading)
        """
        num_envs = data.shape[0]
        
        # è·å–æ‰€æœ‰ç¯å¢ƒçš„dof_pos
        all_dof_pos = data.dof_pos.copy()  # [num_envs, num_dof]
        
        # ä¸ºæ¯ä¸ªç¯å¢ƒæ›´æ–°ç›®æ ‡æ ‡è®°ä½ç½®
        for env_idx in range(num_envs):
            target_x = float(pose_commands[env_idx, 0])
            target_y = float(pose_commands[env_idx, 1])
            target_yaw = float(pose_commands[env_idx, 2])  # å·²ç»æ˜¯è§’åº¦ï¼Œä¸éœ€è¦è½¬æ¢
            
            # æ›´æ–°target_markerçš„DOF: [x, y, yaw]
            # åªéœ€è¦è®¾ç½®æ°´å¹³ä½ç½®å’Œç»•Zè½´çš„æœå‘
            all_dof_pos[env_idx, self._target_marker_dof_start:self._target_marker_dof_end] = [
                target_x, target_y, target_yaw
            ]
        
        # ä¸€æ¬¡æ€§è®¾ç½®æ‰€æœ‰ç¯å¢ƒçš„dof_pos
        data.set_dof_pos(all_dof_pos, self._model)
        # å¿…é¡»è°ƒç”¨forward_kinematicæ‰èƒ½æ›´æ–°bodyçš„pose
        self._model.forward_kinematic(data)

    def _compute_projected_gravity(self, quat: np.ndarray) -> np.ndarray:
        # Motrixå¼•æ“æ ¼å¼: [qx, qy, qz, qw]
        qx, qy, qz, qw = quat[:, 0], quat[:, 1], quat[:, 2], quat[:, 3]
        # é‡åŠ›å‘é‡
        gravity_world = np.array([0.0, 0.0, -1.0], dtype=np.float32)
        vx, vy, vz = gravity_world[0], gravity_world[1], gravity_world[2]

        # è®¡ç®—æ—‹è½¬åå‘é‡ï¼ˆå››å…ƒæ•°æ—‹è½¬å…¬å¼ï¼‰
        rx = (1 - 2*(qy*qy + qz*qz)) * vx + 2*(qx*qy - qw*qz) * vy + 2*(qx*qz + qw*qy) * vz
        ry = 2*(qx*qy + qw*qz) * vx + (1 - 2*(qx*qx + qz*qz)) * vy + 2*(qy*qz - qw*qx) * vz
        rz = 2*(qx*qz - qw*qy) * vx + 2*(qy*qz + qw*qx) * vy + (1 - 2*(qx*qx + qy*qy)) * vz
    
        projected_gravity = np.stack([rx, ry, rz], axis = -1)
        return projected_gravity

    def _compute_terminated(self, state: NpEnvState) -> NpEnvState:
        data = state.data

        terminated = np.zeros(self._num_envs, dtype=bool)
        truncated  = np.zeros(self._num_envs, dtype=bool)

        truncated |= self._check_timeout(state)
        terminated |= self._check_dof_velocity_failure(data)
        terminated |= self._check_base_contact_failure(data)
        terminated |= self._check_side_flip_failure(data)

        self._debug_termination(
            state,
            truncated=truncated,
            terminated=terminated,
        )

        return state.replace(
            terminated=terminated,
            truncated=truncated,   # ğŸ‘ˆ å¼ºçƒˆå»ºè®®åŠ 
        )

    def _check_timeout(self, state: NpEnvState) -> np.ndarray:
        if not self._cfg.max_episode_steps:
            return np.zeros(self._num_envs, dtype=bool)
        return state.info["steps"] >= self._cfg.max_episode_steps

     # æ£€æŸ¥DOFé€Ÿåº¦æ˜¯å¦è¶…é™ï¼ˆé˜²æ­¢inf/æ•°å€¼å‘æ•£ï¼‰ 
    def _check_dof_velocity_failure(self, data) -> np.ndarray:
        dof_vel = self.get_dof_vel(data)
        vel_max = np.abs(dof_vel).max(axis=1)

        vel_overflow = vel_max > self._cfg.max_dof_vel
        vel_extreme = (
            np.isnan(dof_vel).any(axis=1)
            | np.isinf(dof_vel).any(axis=1)
            | (vel_max > 1e6)
        )
        return vel_overflow | vel_extreme
    
    # æœºå™¨äººåŸºåº§æ¥è§¦åœ°é¢ç»ˆæ­¢
    def _check_base_contact_failure(self, data) -> np.ndarray:
        cquerys = self._model.get_contact_query(data)
        termination_check = cquerys.is_colliding(self.termination_contact)
        termination_check = termination_check.reshape(
            (self._num_envs, self.num_termination_check)
        )
        return termination_check.any(axis=1)
    
    # ä¾§ç¿»ç»ˆæ­¢ï¼šå€¾æ–œè§’åº¦è¶…è¿‡75Â°
    def _check_side_flip_failure(self, data) -> np.ndarray:
        pose = self._body.get_pose(data)
        root_quat = pose[:, 3:7]

        proj_g = self._compute_projected_gravity(root_quat)
        gxy = np.linalg.norm(proj_g[:, :2], axis=1)
        gz = proj_g[:, 2]

        tilt_angle = np.arctan2(gxy, np.abs(gz))
        return tilt_angle > np.deg2rad(75)

    def _debug_termination(self, state, truncated, terminated):
        if not (truncated.any() or terminated.any()):
            return
        if state.info["steps"][0] % 100 != 0:
            return
        print(
            f"[termination] "
            f"terminated={int(terminated.sum())} "
            f"truncated={int(truncated.sum())}"
        )

    def reset(self, data: mtx.SceneData, done: np.ndarray = None) -> tuple[np.ndarray, dict]:
        cfg: AnymalCEnvCfg = self._cfg
        num_envs = data.shape[0]

        # å…ˆç”Ÿæˆæœºå™¨äººçš„åˆå§‹ä½ç½®ï¼ˆåœ¨ä¸–ç•Œåæ ‡ç³»ä¸­ï¼‰
        pos_range = cfg.init_state.pos_randomization_range
        robot_init_x = np.random.uniform(
            pos_range[0], pos_range[2],  # x_min, x_max
            num_envs
        )
        robot_init_y = np.random.uniform(
            pos_range[1], pos_range[3],  # y_min, y_max
            num_envs
        )
        robot_init_pos = np.stack([robot_init_x, robot_init_y], axis=1)  # [num_envs, 2]

        # ç”Ÿæˆç›®æ ‡ä½ç½®ï¼šç›¸å¯¹äºæœºå™¨äººåˆå§‹ä½ç½®çš„åç§»
        # pose_command_range ç°åœ¨è¡¨ç¤ºç›¸å¯¹æœºå™¨äººçš„åç§»èŒƒå›´
        target_offset = np.random.uniform(
            low = cfg.commands.pose_command_range[:2],
            high = cfg.commands.pose_command_range[3:5],
            size = (num_envs, 2)
        )
        target_positions = robot_init_pos + target_offset  # ä¸–ç•Œåæ ‡ç³»ä¸­çš„ç›®æ ‡ä½ç½®

        # ç”Ÿæˆç›®æ ‡æœå‘ï¼ˆç»å¯¹æœå‘ï¼Œæ°´å¹³æ–¹å‘éšæœºï¼‰
        target_headings = np.random.uniform(
            low = cfg.commands.pose_command_range[2],
            high = cfg.commands.pose_command_range[5],
            size = (num_envs, 1)
        )

        pose_commands = np.concatenate([target_positions, target_headings],axis = 1)

        # è®¾ç½®åˆå§‹çŠ¶æ€ - é¿å…ç»™å››å…ƒæ•°æ·»åŠ å™ªå£°
        init_dof_pos = np.tile(self._init_dof_pos, (*data.shape, 1))
        init_dof_vel = np.tile(self._init_dof_vel, (*data.shape, 1))

        # åˆ›å»ºå™ªå£° - ä¸è¦ç»™å››å…ƒæ•°æ·»åŠ å™ªå£°
        noise_pos = np.zeros((*data.shape, self._num_dof_pos), dtype=np.float32)
        
        # target_marker (DOF 0-2): ä¸æ·»åŠ å™ªå£°ï¼Œä¼šåœ¨_update_target_markerä¸­è®¾ç½®
        
        # baseçš„ä½ç½® (DOF 3-5): ä½¿ç”¨å‰é¢ç”Ÿæˆçš„éšæœºåˆå§‹ä½ç½®
        noise_pos[:, 3] = robot_init_x - cfg.init_state.pos[0]  # ç›¸å¯¹é»˜è®¤ä½ç½®çš„åç§»
        noise_pos[:, 4] = robot_init_y - cfg.init_state.pos[1]
        # Zè½´ä¸æ·»åŠ å™ªå£°ï¼Œä¿æŒå›ºå®šé«˜åº¦é¿å…å è½æ„Ÿ
        # baseçš„å››å…ƒæ•° (DOF 6-9): ä¸æ·»åŠ å™ªå£°ï¼Œä¿æŒä¸ºå•ä½å››å…ƒæ•°
        
        # å…³èŠ‚è§’åº¦(DOF 10:)ä¸æ·»åŠ å™ªå£°ï¼Œä¿è¯åˆå§‹ç«™ç«‹ç¨³å®š
        # noise_pos[:, 10:] = 0.0  # å·²ç»åˆå§‹åŒ–ä¸º0

        # æ‰€æœ‰é€Ÿåº¦éƒ½è®¾ä¸º0ï¼Œç¡®ä¿å®Œå…¨é™æ­¢
        noise_vel = np.zeros((*data.shape, self._num_dof_vel), dtype=np.float32)

        dof_pos = init_dof_pos + noise_pos
        dof_vel = init_dof_vel + noise_vel
        
        # å½’ä¸€åŒ–baseçš„å››å…ƒæ•°ï¼ˆDOF 6-9ï¼‰
        # æ–°çš„DOFç»“æ„ï¼štarget_markerå 0-2, base_poså 3-5, base_quatå 6-9
        for env_idx in range(num_envs):
            quat = dof_pos[env_idx, self._base_quat_dof_start:self._base_quat_dof_end]  # [qx, qy, qz, qw]
            quat_norm = np.linalg.norm(quat) # è¿”å› sqrt(q0^2 + q1^2 + q2^2 + q3^2)
            if quat_norm > 1e-6:  # é¿å…é™¤ä»¥é›¶
                dof_pos[env_idx, self._base_quat_dof_start:self._base_quat_dof_end] = quat / quat_norm
            else:
                dof_pos[env_idx, self._base_quat_dof_start:self._base_quat_dof_end] = np.array([1.0, 0.0, 0.0, 0.0], dtype=np.float32)  # é»˜è®¤å•ä½å››å…ƒæ•°
            
            # å½’ä¸€åŒ–ç®­å¤´çš„å››å…ƒæ•°ï¼ˆå¦‚æœç®­å¤´bodyå­˜åœ¨ï¼‰
            if self._robot_arrow_body is not None:
                # robot_heading_arrowçš„å››å…ƒæ•°ï¼ˆDOF 25-28: qx, qy, qz, qwï¼‰
                robot_arrow_quat = dof_pos[env_idx, self._robot_arrow_dof_start+3:self._robot_arrow_dof_end]
                quat_norm = np.linalg.norm(robot_arrow_quat)
                if quat_norm > 1e-6:
                    dof_pos[env_idx, self._robot_arrow_dof_start+3:self._robot_arrow_dof_end] = robot_arrow_quat / quat_norm
                else:
                    dof_pos[env_idx, self._robot_arrow_dof_start+3:self._robot_arrow_dof_end] = np.array([0.0, 0.0, 0.0, 1.0], dtype=np.float32)
                
                # desired_heading_arrowçš„å››å…ƒæ•°ï¼ˆDOF 32-35: qx, qy, qz, qwï¼‰
                desired_arrow_quat = dof_pos[env_idx, self._desired_arrow_dof_start+3:self._desired_arrow_dof_end]
                quat_norm = np.linalg.norm(desired_arrow_quat)
                if quat_norm > 1e-6:
                    dof_pos[env_idx, self._desired_arrow_dof_start+3:self._desired_arrow_dof_end] = desired_arrow_quat / quat_norm
                else:
                    dof_pos[env_idx, self._desired_arrow_dof_start+3:self._desired_arrow_dof_end] = np.array([0.0, 0.0, 0.0, 1.0], dtype=np.float32)

        data.reset(self._model)
        data.set_dof_vel(dof_vel)
        data.set_dof_pos(dof_pos, self._model)
        self._model.forward_kinematic(data)
        
        obs=self._compute_obs(data,pose_commands)
        
        root_pos, root_quat, root_vel = self._extract_root_state(data)
        robot_position = root_pos[:, :2]
        target_position = pose_commands[:, :2]
        position_error = target_position - robot_position
        distance_to_target = np.linalg.norm(position_error, axis=1)  # [num_envs]
        info = {
            "last_dof_vel": np.zeros((num_envs, self._num_action), dtype=np.float32),
            "pose_commands": pose_commands,
            "last_actions": np.zeros((num_envs, self._num_action), dtype=np.float32),
            "steps": np.zeros(num_envs, dtype=np.int32),
            "current_actions": np.zeros((num_envs, self._num_action), dtype=np.float32),
            "ever_reached": np.zeros(num_envs, dtype=bool),
            "min_distance": distance_to_target.copy(),  # åˆå§‹åŒ–æœ€å°è·ç¦»
        }

        return obs,info
      
       

    def _compute_obs(self,data: mtx.SceneData, pose_commands: np.ndarray,position_threshold=0.1,heading_threshold = np.deg2rad(15),last_actions:np.ndarray=None)-> np.ndarray:
        num_envs = data.shape[0]
        if last_actions is None:
            last_actions = np.zeros((num_envs, self._num_action), dtype=np.float32)
        # è·å–æ ¹èŠ‚ç‚¹çŠ¶æ€
        root_pos, root_quat, root_vel = self._extract_root_state(data)

        # å…³èŠ‚çŠ¶æ€ï¼ˆè…¿éƒ¨å…³èŠ‚ï¼‰
        joint_pos = self.get_dof_pos(data)
        joint_vel = self.get_dof_vel(data)
        joint_pos_rel = joint_pos - self.default_angles
        
        # è·å–ä¼ æ„Ÿå™¨æ•°æ®
        base_lin_vel = root_vel[:, :3]
        gyro = self._model.get_sensor_value(self._cfg.sensor.base_gyro, data)
        projected_gravity = self._compute_projected_gravity(root_quat)
        
        self._compute_commands(data,pose_commands)

        desired_vel_xy,desired_vel_xy,reached_all,velocity_commands=self._compute_velocity_commands(position_threshold,heading_threshold)
         # æ›´æ–°ç›®æ ‡ä½ç½®æ ‡è®°
        self._update_target_marker(data, pose_commands)
        # æ›´æ–°ç®­å¤´å¯è§†åŒ–ï¼ˆä¸å½±å“ç‰©ç†ï¼‰
        base_lin_vel_xy = base_lin_vel[:, :2]
        self._update_heading_arrows(data, root_pos, desired_vel_xy, base_lin_vel_xy)
        
        # å½’ä¸€åŒ–è§‚æµ‹ï¼ˆ
        noisy_linvel = base_lin_vel * self._cfg.normalization.lin_vel
        noisy_gyro = gyro * self._cfg.normalization.ang_vel
        noisy_joint_angle = joint_pos_rel * self._cfg.normalization.dof_pos
        noisy_joint_vel = joint_vel * self._cfg.normalization.dof_vel
        command_normalized = velocity_commands * self.commands_scale
        
        # è®¡ç®—ä»»åŠ¡ç›¸å…³è§‚æµ‹
        position_error_normalized = self.position_error / 5.0
        heading_error_normalized = self.heading_diff / np.pi
        distance_normalized = np.clip(self.distance_to_target / 5.0, 0, 1)
        reached_flag = reached_all.astype(np.float32)
        
        # è®¡ç®—æ˜¯å¦è¾¾åˆ°zero_angæ ‡å‡†
        stop_ready = np.logical_and(
            reached_all,
            np.abs(gyro[:, 2]) < 5e-2
        )
        stop_ready_flag = stop_ready.astype(np.float32)

        obs = np.concatenate(
            [
                noisy_linvel,       # 3
                noisy_gyro,         # 3
                projected_gravity,  # 3
                noisy_joint_angle,  # 12
                noisy_joint_vel,    # 12
                last_actions,       # 12
                command_normalized, # 3
                position_error_normalized,  # 2
                heading_error_normalized[:, np.newaxis],  # 1
                distance_normalized[:, np.newaxis],  # 1
                reached_flag[:, np.newaxis],  # 1
                stop_ready_flag[:, np.newaxis],  # 1
            ],
            axis=-1,
        )
        assert obs.shape == (num_envs, 54)

        return obs

    def _compute_commands(self,data: mtx.SceneData, pose_commands: np.ndarray):
        # è·å–æ ¹èŠ‚ç‚¹çŠ¶æ€
        root_pos, root_quat, root_vel = self._extract_root_state(data)
        base_lin_vel = root_vel[:, :3]
        # è®¡ç®—é€Ÿåº¦å‘½ä»¤ï¼ˆä¸update_stateä¸€è‡´ï¼‰
        robot_position = root_pos[:, :2]
        robot_heading = self._get_heading_from_quat(root_quat)
        target_position = pose_commands[:, :2]
        target_heading = pose_commands[:, 2]
        
        self.position_error = target_position - robot_position
        self.distance_to_target = np.linalg.norm(self.position_error, axis=1)  # [num_envs]
        self.desired_vel_xy = np.clip(self.position_error * 1.0, -1.0, 1.0)

        self.heading_diff = target_heading - robot_heading
        self.heading_diff = np.where(self.heading_diff > np.pi, self.heading_diff - 2*np.pi, self.heading_diff)
        self.heading_diff = np.where(self.heading_diff < -np.pi, self.heading_diff + 2*np.pi, self.heading_diff)
        self.desired_yaw_rate = np.clip(self.heading_diff * 1.0, -1.0, 1.0)
 

    def _compute_velocity_commands(self,position_threshold=0.1,heading_threshold = np.deg2rad(15)):
        reached_position = self.distance_to_target < position_threshold  # [num_envs]
        desired_vel_xy = np.where(reached_position[:, np.newaxis], 0.0, self.desired_vel_xy)  # åˆ°è¾¾åé€Ÿåº¦ä¸º0
        
        reached_heading = np.abs(self.heading_diff) < heading_threshold  # [num_envs]
          
        reached_all = np.logical_and(reached_position, reached_heading)
        desired_yaw_rate = np.where(reached_all, 0.0, self.desired_yaw_rate)  # åˆ°è¾¾åè§—é€Ÿåº¦ä¸º0
        desired_vel_xy = np.where(reached_all[:, np.newaxis], 0.0, desired_vel_xy)  # åˆ°è¾¾åé€Ÿåº¦ä¸º0
        
        # ç¡®ä¿ desired_yaw_rate æ˜¯1ç»´æ•°ç»„
        if desired_yaw_rate.ndim > 1:
            desired_yaw_rate = desired_yaw_rate.flatten()
        
        velocity_commands = np.concatenate(
            [desired_vel_xy, desired_yaw_rate[:, np.newaxis]], axis=-1
        )
        return desired_vel_xy,desired_vel_xy,reached_all,velocity_commands

        
     # ------------ reward functions----------------
    def get_local_linvel(self, data: mtx.SceneData) -> np.ndarray:
        return self._model.get_sensor_value(self.cfg.sensor.base_linvel, data)

    def get_gyro(self, data: mtx.SceneData) -> np.ndarray:
        return self._model.get_sensor_value(self._cfg.sensor.base_gyro, data)
    
    def _reward_lin_vel_z(self, data):
        # Penalize z axis base linear velocity
        return np.square(self.get_local_linvel(data)[:, 2])

    def _reward_ang_vel_xy(self, data):
        # Penalize xy axes base angular velocity
        return np.sum(np.square(self.get_gyro(data)[:, :2]), axis=1)

    def _reward_orientation(self, data):
        # å°†é‡åŠ›å‘é‡ä»ä¸–ç•Œåæ ‡ç³»å˜æ¢åˆ°åŸºåº§å±€éƒ¨åæ ‡ç³»
        # å°†x,yåˆ†é‡çš„å¹³æ–¹
        # Penalize non flat base orientation
        pose = self._body.get_pose(data)
        base_quat = pose[:, 3:7]
        gravity = Quaternion.rotate_inverse(base_quat, np.array([0, 0, -1], dtype=np.float32))
        return np.sum(np.square(gravity[:, :2]), axis=1)

    def _reward_torques(self, data: mtx.SceneData):
        # Penalize torques
        return np.sum(np.square(data.actuator_ctrls), axis=1)

    def _reward_dof_vel(self, data):
        # Penalize dof velocities
        return np.sum(np.square(self.get_dof_vel(data)), axis=1)

    def _reward_dof_acc(self, data, info):
        # Penalize dof accelerations
        return np.sum(
            np.square((info["last_dof_vel"] - self.get_dof_vel(data)) / self.cfg.ctrl_dt),
            axis=1,
        )

    def _reward_action_rate(self, info: dict):
        # Penalize changes in actions
        action_diff = info["current_actions"] - info["last_actions"]
        return np.sum(np.square(action_diff), axis=1)

    def _reward_termination(self, data):
        terminated = np.zeros(self._num_envs, dtype=bool)
        terminated |= self._check_dof_velocity_failure(data)
        terminated |= self._check_base_contact_failure(data)
        terminated |= self._check_side_flip_failure(data)
        return terminated

    # def _reward_feet_air_time(self, commands: np.ndarray, info: dict):
    #     # Reward long steps
    #     feet_air_time = info["feet_air_time"]
    #     first_contact = (feet_air_time > 0.0) * info["contacts"]
    #     # reward only on first contact with the ground
    #     rew_airTime = np.sum((feet_air_time - 0.5) * first_contact, axis=1)
    #     # no reward for zero command
    #     rew_airTime *= np.linalg.norm(commands[:, :2], axis=1) > 0.1
    #     return rew_airTime

    def _reward_tracking_lin_vel(self, data, commands: np.ndarray):
        # Tracking of linear velocity commands (xy axes)
        lin_vel_error = np.sum(np.square(commands[:, :2] - self.get_local_linvel(data)[:, :2]), axis=1)
        return np.exp(-lin_vel_error / self.cfg.reward_config.tracking_sigma)

    def _reward_tracking_ang_vel(self, data, commands: np.ndarray):
        # Tracking of angular velocity commands (yaw)
        ang_vel_error = np.square(commands[:, 2] - self.get_gyro(data)[:, 2])
        return np.exp(-ang_vel_error / self.cfg.reward_config.tracking_sigma)

    def _reward_stand_still(self, data, commands: np.ndarray):
        # Penalize motion at zero commands
        return np.sum(np.abs(self.get_dof_pos(data) - self.default_angles), axis=1) * (
            np.linalg.norm(commands, axis=1) < 0.1
        )

    def _reward_arrival_bonus(self,info,reached_all):
    # é¦–æ¬¡åˆ°è¾¾ä½ç½®çš„ä¸€æ¬¡æ€§å¥–åŠ±
        info["ever_reached"] = info.get("ever_reached", np.zeros(self._num_envs, dtype=bool))
        first_time_reach = np.logical_and(reached_all, ~info["ever_reached"])
        info["ever_reached"] = np.logical_or(info["ever_reached"], reached_all)
        return first_time_reach
    

    def _reward_approch(self,info):
        # è·ç¦»æ¥è¿‘å¥–åŠ±ï¼šæ¿€åŠ±é è¿‘ç›®æ ‡
        # ä½¿ç”¨å†å²æœ€è¿‘è·ç¦»æ¥è®¡ç®—è¿›æ­¥
        if "min_distance" not in info:
            info["min_distance"] = self.distance_to_target.copy()
        distance_improvement = info["min_distance"] - self.distance_to_target
        info["min_distance"] = np.minimum(info["min_distance"], self.distance_to_target)
        approach_reward = np.clip(distance_improvement * 4.0, -1.0, 1.0)  
        return approach_reward
    
    def _reward_stop_bonus(self,data,reached_all):
        base_lin_vel=self.get_local_linvel(data)
        gyro=self.get_gyro(data)
        # åˆ°è¾¾ä¸åœæ­¢åˆ¤å®šï¼ˆå¥–åŠ±åŠ æˆï¼‰
        speed_xy = np.linalg.norm(base_lin_vel[:, :2], axis=1)
        zero_ang_mask = np.abs(gyro[:, 2]) < 0.05  # æ”¾å®½åˆ°0.05 rad/s â‰ˆ 2.86Â°/s
        zero_ang_bonus = np.where(np.logical_and(reached_all, zero_ang_mask), 6.0, 0.0)
        stop_base = 2 * (0.8 * np.exp(- (speed_xy / 0.2)**2) + 1.2 * np.exp(- (np.abs(gyro[:, 2]) / 0.1)**4))
        stop_bonus = np.where(reached_all, stop_base + zero_ang_bonus, 0.0)
        return stop_bonus

    # def _reward_hip_pos(self, data, commands: np.ndarray):
    #     return (0.8 - np.abs(commands[:, 1])) * np.sum(
    #         np.square(self.get_dof_pos(data)[:, self.hip_indices] - self.default_angles[self.hip_indices]),
    #         axis=1,
    #     )

    # def _reward_calf_pos(self, data, commands: np.ndarray):
    #     return (0.8 - np.abs(commands[:, 1])) * np.sum(
    #         np.square(self.get_dof_pos(data)[:, self.calf_indices] - self.default_angles[self.calf_indices]),
    #         axis=1,
    #     )

    def border_check(self, data, info: dict):
        # check whether the robot reaching into the terrain border and change the move direction
        border_size = 19.0
        position = self._body.get_position(data)
        is_out = (np.square(position[:, :2]) > border_size**2).any(axis=1)
        info["commands"][is_out] = [0, 0, 0]

  